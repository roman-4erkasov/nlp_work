{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c9eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import config\n",
    "import dataset\n",
    "import engine\n",
    "from model import Model\n",
    "\n",
    "TRAINING_FILE = \"./ner_dataset.csv\"\n",
    "\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 1  # 10\n",
    "BASE_MODEL_PATH = \"./bert-base-uncased\"\n",
    "MODEL_PATH = \"model.bin\"\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079aae3",
   "metadata": {},
   "source": [
    "# 1. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e9923",
   "metadata": {},
   "source": [
    "## 1.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80126af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>NaN</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>NaN</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence #           Word  POS Tag\n",
       "0        Sentence: 1      Thousands  NNS   O\n",
       "1                NaN             of   IN   O\n",
       "2                NaN  demonstrators  NNS   O\n",
       "3                NaN           have  VBP   O\n",
       "4                NaN        marched  VBN   O\n",
       "...              ...            ...  ...  ..\n",
       "1048570          NaN           they  PRP   O\n",
       "1048571          NaN      responded  VBD   O\n",
       "1048572          NaN             to   TO   O\n",
       "1048573          NaN            the   DT   O\n",
       "1048574          NaN         attack   NN   O\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAINING_FILE, encoding=\"latin-1\")#[:150_000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789c3a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #           Word  POS Tag\n",
       "0            Sentence: 1      Thousands  NNS   O\n",
       "1            Sentence: 1             of   IN   O\n",
       "2            Sentence: 1  demonstrators  NNS   O\n",
       "3            Sentence: 1           have  VBP   O\n",
       "4            Sentence: 1        marched  VBN   O\n",
       "...                  ...            ...  ...  ..\n",
       "1048570  Sentence: 47959           they  PRP   O\n",
       "1048571  Sentence: 47959      responded  VBD   O\n",
       "1048572  Sentence: 47959             to   TO   O\n",
       "1048573  Sentence: 47959            the   DT   O\n",
       "1048574  Sentence: 47959         attack   NN   O\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00fcf5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #           Word  POS  Tag\n",
       "0            Sentence: 1      Thousands   19   16\n",
       "1            Sentence: 1             of   10   16\n",
       "2            Sentence: 1  demonstrators   19   16\n",
       "3            Sentence: 1           have   35   16\n",
       "4            Sentence: 1        marched   34   16\n",
       "...                  ...            ...  ...  ...\n",
       "1048570  Sentence: 47959           they   22   16\n",
       "1048571  Sentence: 47959      responded   32   16\n",
       "1048572  Sentence: 47959             to   29   16\n",
       "1048573  Sentence: 47959            the    7   16\n",
       "1048574  Sentence: 47959         attack   16   16\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_pos = preprocessing.LabelEncoder()\n",
    "enc_tag = preprocessing.LabelEncoder()\n",
    "df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\n",
    "df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e22fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "pos = df.groupby(\"Sentence #\")[\"POS\"].apply(list).values\n",
    "tag = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c3848",
   "metadata": {},
   "source": [
    "## 1.2 Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66319435",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = {\n",
    "    \"enc_pos\": enc_pos,\n",
    "    \"enc_tag\": enc_tag\n",
    "}\n",
    "\n",
    "with open(\"meta.bin\", \"wb\") as fp:\n",
    "    pkl.dump(meta_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef048653",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos = len(list(enc_pos.classes_))\n",
    "n_tag = len(list(enc_tag.classes_))\n",
    "\n",
    "(\n",
    "    train_sentences, test_sentences,\n",
    "    train_pos,test_pos,\n",
    "    train_tag, test_tag\n",
    ") = model_selection.train_test_split(\n",
    "    sentences, pos, tag, random_state=1337, test_size=0.1\n",
    ")\n",
    "\n",
    "train_dataset = dataset.Dataset(\n",
    "    texts=train_sentences, pos=train_pos, tags=train_tag,\n",
    "    tokenizer=TOKENIZER, max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=4\n",
    ")\n",
    "\n",
    "valid_dataset = dataset.Dataset(\n",
    "    texts=test_sentences, pos=test_pos, tags=test_tag,\n",
    "    tokenizer=TOKENIZER, max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=VALID_BATCH_SIZE, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d486d868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = Model(BASE_MODEL_PATH, n_tag=n_tag, n_pos=n_pos)\n",
    "model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "num_train_steps = int(\n",
    "    len(train_sentences) \n",
    "    / \n",
    "    TRAIN_BATCH_SIZE * EPOCHS\n",
    ")\n",
    "\n",
    "optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f50b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [10:42<00:00,  2.10it/s]\n",
      "100%|██████████| 600/600 [00:32<00:00, 18.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.245129476937212 Valid Loss = 0.11209187394939363\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train_loss = engine.train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "    test_loss = engine.eval_fn(valid_data_loader, model, device)\n",
    "    print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d7bfa",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c06155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ivan visited Vietnam a week ago. He took a room in hotel Matiott.\n",
      "['ivan', 'visited', 'vietnam', 'a', 'week', 'ago', '.', 'he', 'took', 'a', 'room', 'in', 'hotel', 'mat', '##iot', '##t', '.']\n",
      "[101, 100, 4716, 100, 1037, 2733, 100, 100, 2165, 1037, 2282, 1999, 3309, 100, 102]\n"
     ]
    }
   ],
   "source": [
    "with open(\"meta.bin\",\"rb\") as fp:\n",
    "    meta_data = joblib.load(fp)\n",
    "enc_pos = meta_data[\"enc_pos\"]\n",
    "enc_tag = meta_data[\"enc_tag\"]\n",
    "\n",
    "n_pos = len(list(enc_pos.classes_))\n",
    "n_tag = len(list(enc_tag.classes_))\n",
    "\n",
    "sentence = \"Ivan visited Vietnam a week ago. He took a room in hotel Matiott.\"\n",
    "sentence_tok = sentence.split()\n",
    "tokenized_sentence = TOKENIZER.encode(sentence_tok)\n",
    "\n",
    "print(sentence)\n",
    "print(TOKENIZER.tokenize(sentence))\n",
    "print(tokenized_sentence)\n",
    "\n",
    "test_dataset = dataset.Dataset(\n",
    "    texts=[sentence_tok], \n",
    "    pos=[[0] * len(sentence_tok)], \n",
    "    tags=[[0] * len(sentence_tok)],\n",
    "    tokenizer=TOKENIZER, \n",
    "    max_len=MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cdb3d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-per' 'O' 'B-geo' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B-org']\n",
      "['NNP' 'VBD' 'NNP' 'DT' 'NN' 'RB' ',' 'PRP' 'VBD' 'DT' 'NN' 'IN' 'NNP']\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = Model(BASE_MODEL_PATH, n_tag=n_tag, n_pos=n_pos)\n",
    "model.load_state_dict(torch.load(config.MODEL_PATH))\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = test_dataset[0]\n",
    "    for k, v in data.items():\n",
    "        data[k] = v.to(device).unsqueeze(0)\n",
    "    tag, pos, _ = model(**data)\n",
    "\n",
    "    print(\n",
    "        enc_tag.inverse_transform(\n",
    "            tag.argmax(2).cpu().numpy().reshape(-1)\n",
    "        )[1:len(tokenized_sentence)-1]\n",
    "    )\n",
    "    print(\n",
    "        enc_pos.inverse_transform(\n",
    "            pos.argmax(2).cpu().numpy().reshape(-1)\n",
    "        )[1:len(tokenized_sentence)-1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15ac47",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We used only 1 epoch, but we got quite sensible result. So fine tuning helps to get higher quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbd4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6eb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
